<!doctype html>
<html lang="en">

<head>
 <meta charset="utf-8">

 <title>Hands-on Workshop</title>

 <meta name="description" content="Apache Kafka">
 <meta name="author" content="Kiruthika Samapathy">

 <meta name="apple-mobile-web-app-capable" content="yes" />
 <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

 <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

 <link rel="stylesheet" href="css/reveal.css">
 <link rel="stylesheet" href="css/theme/thoughtworks.css" id="theme">

 <!-- Code syntax highlighting -->
 <link rel="stylesheet" href="lib/css/zenburn.css">

 <!-- Printing and PDF exports -->
 <script>
  var link = document.createElement('link');
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
  document.getElementsByTagName('head')[0].appendChild(link);
 </script>

 <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

 <div class="reveal">

  <!-- Any section element inside of this container is displayed as a slide -->
  <div class="slides">

   <section class="title">
    <h1>Apache Kafka</h1>
    <h3>High-throughput messaging system <i>or</i> distributed commit logs?</h3>
   </section>

   <section class="title">
    <h1>why another tool?</h1>
    <h3>Why are we here? What are we going to do?</h3>
    <aside class="notes">
     <ul>
      <li>A queue per consumer</li>
      <li>Messaging sytem is heavy</li>
      <li>Consumers at different consumption pace</li>
      <i>commit log</i>
     </ul>
    </aside>
   </section>

   <section>
    <h2>How is Kafka different?</h2>
    <br>
    <ul>
     <li>Explicitly distributed</li>
     <li>Persistent messages as the common case</li>
     <li>Partitioned</li>
     <li>Replicated</li>
     <li>Dumb pipelines</li>
     <i>commit log</i>
    </ul>
    <aside class="notes">
     central commit log
     <br> break apart your entire infrastructure
     <br> thousands of terrabytes of data
     <br> millions of requests per second
     <br>
     <br> all your systems can dump data into it, why because it is cheap, easy to scale, predictable
     <br> kafka assumes that producers, brokers and consumers are all spread across multiple machines
     <br> State information as what is being consumed is part of consumer and not data pipeline
     <br>
     <br> Prodcers, brokers and consumers run as a logical group with the help of Zookeeper
     <br>
    </aside>
   </section>

   <section>
    <h2>Kafka dictionary</h2>
    <br>
    <ul>
     <li>Broker - Kafka Server</li>
     <li>Producer</li>
     <li>Consumer</li>
     <li>Topics - Multiple partitions - Partitions replicated </li>
     <li>Broker leader - Broker followers - ISR </li>
    </ul>
    <aside class="notes">
     leader - current broker in-charge of the partition
     <br> all producers to the given partition talk to the broker leader
     <br> replication - broker consumes from leader
     <br> list of broker replicas - that are upto date with the leader
     <br>
    </aside>
   </section>

   <section>
    <h2>Decoupled data pipeline</h2>
    <br>
    <img width="1400" data-src="images/kafka_overview.jpg" alt="Kafka overview" style="border:0">
    <aside class="notes">
     it is a quite simple abstraction
     <br> Producers send messages to Kafka clusters
     <br> Kafka cluster holds these messages for specified time
     <br> Consumers read content from cluster on their own pace
     <br> producer need not know anything abt downstream pipeline
     <br>
     <br>
    </aside>
   </section>

   <section>
    <h2>Topic and Partitions</h2>
    <img width="1000" data-src="images/topics_partitions_overview.jpg" alt="Kafka overview" style="border:0">
    <aside class="notes">
     topic is the virtual category, it is the key abstraction
     <br> Kafka topic is a append-only or write-ahead log
     <br> so ordered is guaranteed at the partition level
     <br>
     <br> partitions are log files on the disk
     <br> Every record is a key-value pair, key determines the partition
     <br> every record has an offset number - consumer uses this offset to determine its position
     <br> key could be computed randomly/producer might specify the key explicitly
     <br>
    </aside>
   </section>

   <section>
    <h2>Topic and Partitions</h2>
    <img width="1000" data-src="images/topics_partitions_detail.jpg" alt="Kafka overview" style="border:0">
    <aside class="notes">
     topic is the virtual category, it is the key abstraction
     <br> Kafka topic is a append-only or write-ahead log
     <br> so ordered is guaranteed at the partition level
     <br>
     <br> partitions are log files on the disk
     <br> Every record is a key-value pair, key determines the partition
     <br> every record has an offset number - consumer uses this offset to determine its position
     <br> key could be computed randomly/producer might specify the key explicitly
     <br> Messages are simply byte arrays and the developers can use them to store any object in any format – with String, JSON, and Avro the most common
    </aside>
   </section>

   <section>
    <h2>Topic and Partitions</h2>
    <img width="800" data-src="images/commit_log.jpg" alt="Kafka overview" style="border:0">
    <aside class="notes">
    </aside>
   </section>

   <section>
    <h2>Eco system</h2>
    <br>
    <ul>
     <li>Producers - Push data to broker</li>
     <ul>
      <li>Asynchronous/Synchronous send</li>
      <li>Batching</li>
      <li>Compression</li>
      <li>Replication</li>
     </ul>
    </ul>
    <aside class="notes">
     1. Producers
     <br> lots of other customization options
     <br> How is it different from other messaging queues? In a typical messaging system, queue will push messages to consumers and maintain all other associated metadata
     <br> Here, consumers pull messsages
     <br>
    </aside>
   </section>

   <section>
    <h2>Eco system</h2>
    <br>
    <ul>
     <li>Consumers - Pull data from broker</li>
     <ul>
      <li>Asynchronous/Synchronous send</li>
      <li>Batching</li>
      <li>Compression</li>
      <li>Replication</li>
     </ul>
    </ul>
    <aside class="notes">
     Each consumer process belongs to a consumer group
     <br> each message is delivered to exactly one process within every consumer group
     <br> In an ideal world, there will be multiple logical consumer groups, each consisting of a cluster of consuming machines
     <br> In the case of large data that no matter how many consumers a topic has, a message is stored only a single time.
     <br>
    </aside>
   </section>

   <section>
    <h2>Where to use?</h2>
    <br>
    <ul>
     <li>Real time event/log aggregations</li>
     <li>Speed layer in the Lambda architecture</li>
     <li>Real time news feeds/metrics/alerts/monitoring</li>
     <li>Data loading for data processing systems</li>
     <li>Event sourcing</li>
     <li>Commit logs</li>
    </ul>
    <aside class="notes">
     no real-time data processing tool is complete without Kafka integration
     <br> best suited when multiple consumers, as that is what it is best optimized for
     <br> commit logs - database state capture
     <br>
     <br> Because Kafka topics are very cheap from a performance and overhead standpoint,
     <br> it’s possible for us to create as many queues as we want, scaled to the performance we want
     <br> and optimizing resource utilization across the system. Because they can be created dynamically,
     <br> we can make our business rules very flexible.
     <br>
    </aside>
   </section>

   <!-- END OF TUTORIAL SLIDES -->

  </div>

 </div>

 <script src="lib/js/head.min.js"></script>
 <script src="js/reveal.js"></script>

 <script>
  // Full list of configuration options available at:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
   controls: true,
   progress: true,
   history: true,
   center: true,
   hideAddressBar: true,

   transition: 'slide', // none/fade/slide/convex/concave/zoom

   // Optional reveal.js plugins
   dependencies: [{
    src: 'lib/js/classList.js',
    condition: function() {
     return !document.body.classList;
    }
   }, {
    src: 'plugin/markdown/marked.js',
    condition: function() {
     return !!document.querySelector('[data-markdown]');
    }
   }, {
    src: 'plugin/markdown/markdown.js',
    condition: function() {
     return !!document.querySelector('[data-markdown]');
    }
   }, {
    src: 'plugin/highlight/highlight.js',
    async: true,
    condition: function() {
     return !!document.querySelector('pre code');
    },
    callback: function() {
     hljs.initHighlightingOnLoad();
    }
   }, {
    src: 'plugin/zoom-js/zoom.js',
    async: true
   }, {
    src: 'plugin/notes/notes.js',
    async: true
   }]
  });
 </script>

</body>

</html>
